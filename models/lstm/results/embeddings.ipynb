{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T16:13:22.817260Z",
     "start_time": "2024-05-19T16:13:19.569688Z"
    }
   },
   "source": [
    "import torch\n",
    "import json\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "\n",
    "scipy.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T16:13:23.476492Z",
     "start_time": "2024-05-19T16:13:23.246837Z"
    }
   },
   "source": [
    "checkpoint = torch.load('./../data/models/pytorch_spanish_spacy_30000.tar')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T16:13:25.392164Z",
     "start_time": "2024-05-19T16:13:25.390077Z"
    }
   },
   "source": [
    "weights = checkpoint[\"model_state_dict\"][\"embed.W\"]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T16:13:26.654921Z",
     "start_time": "2024-05-19T16:13:26.625658Z"
    }
   },
   "source": [
    "with open('./../data/models/pytorch_spanish_spacy_30000.json', 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "vocabulary = OrderedDict(sorted(vocabulary.items(), key=lambda x: x[1]))"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:01:08.453202Z",
     "start_time": "2024-05-16T19:01:08.450410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T16:21:46.367466Z",
     "start_time": "2024-05-19T16:20:07.407446Z"
    }
   },
   "source": [
    "with open(\"./../data/models/embeddings.txt\", \"w\") as f:\n",
    "    f.write(f\"{weights.shape[0]} {weights.shape[1]}\\n\")\n",
    "    for i, (word, vector) in enumerate(zip(vocabulary.keys(), weights)):\n",
    "        vector_str = ' '.join(str(x) for x in vector.tolist())\n",
    "        f.write(f'{word} {vector_str}\\n')"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T16:16:01.028157Z",
     "start_time": "2024-05-19T16:15:46.905950Z"
    }
   },
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(\"./../data/models/embeddings.txt\", binary=False)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,) into shape (400,)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KeyedVectors\n\u001B[0;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mKeyedVectors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_word2vec_format\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./../data/models/embeddings.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbinary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:1719\u001B[0m, in \u001B[0;36mKeyedVectors.load_word2vec_format\u001B[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001B[0m\n\u001B[1;32m   1672\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m   1673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_word2vec_format\u001B[39m(\n\u001B[1;32m   1674\u001B[0m         \u001B[38;5;28mcls\u001B[39m, fname, fvocab\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, binary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf8\u001B[39m\u001B[38;5;124m'\u001B[39m, unicode_errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1675\u001B[0m         limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, datatype\u001B[38;5;241m=\u001B[39mREAL, no_header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1676\u001B[0m     ):\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001B[39;00m\n\u001B[1;32m   1678\u001B[0m \n\u001B[1;32m   1679\u001B[0m \u001B[38;5;124;03m    Warnings\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1717\u001B[0m \n\u001B[1;32m   1718\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1719\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_word2vec_format\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1720\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfvocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbinary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbinary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43municode_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43municode_errors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1721\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatatype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatatype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mno_header\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_header\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1722\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:2069\u001B[0m, in \u001B[0;36m_load_word2vec_format\u001B[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001B[0m\n\u001B[1;32m   2065\u001B[0m         _word2vec_read_binary(\n\u001B[1;32m   2066\u001B[0m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001B[1;32m   2067\u001B[0m         )\n\u001B[1;32m   2068\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2069\u001B[0m         \u001B[43m_word2vec_read_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcounts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvector_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatatype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43municode_errors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2070\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kv\u001B[38;5;241m.\u001B[39mvectors\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(kv):\n\u001B[1;32m   2071\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m   2072\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mduplicate words detected, shrinking matrix size from \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2073\u001B[0m         kv\u001B[38;5;241m.\u001B[39mvectors\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlen\u001B[39m(kv),\n\u001B[1;32m   2074\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:1975\u001B[0m, in \u001B[0;36m_word2vec_read_text\u001B[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001B[0m\n\u001B[1;32m   1973\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munexpected end of input; is count incorrect or file otherwise damaged?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1974\u001B[0m word, weights \u001B[38;5;241m=\u001B[39m _word2vec_line_to_vector(line, datatype, unicode_errors, encoding)\n\u001B[0;32m-> 1975\u001B[0m \u001B[43m_add_word_to_kv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcounts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:1911\u001B[0m, in \u001B[0;36m_add_word_to_kv\u001B[0;34m(kv, counts, word, weights, vocab_size)\u001B[0m\n\u001B[1;32m   1909\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mduplicate word \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in word2vec file, ignoring all but first\u001B[39m\u001B[38;5;124m\"\u001B[39m, word)\n\u001B[1;32m   1910\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m-> 1911\u001B[0m word_id \u001B[38;5;241m=\u001B[39m \u001B[43mkv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m counts \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1914\u001B[0m     \u001B[38;5;66;03m# Most common scenario: no vocab file given. Just make up some bogus counts, in descending order.\u001B[39;00m\n\u001B[1;32m   1915\u001B[0m     \u001B[38;5;66;03m# TODO (someday): make this faking optional, include more realistic (Zipf-based) fake numbers.\u001B[39;00m\n\u001B[1;32m   1916\u001B[0m     word_count \u001B[38;5;241m=\u001B[39m vocab_size \u001B[38;5;241m-\u001B[39m word_id\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:562\u001B[0m, in \u001B[0;36mKeyedVectors.add_vector\u001B[0;34m(self, key, vector)\u001B[0m\n\u001B[1;32m    560\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_to_key[target_index] \u001B[38;5;241m=\u001B[39m key\n\u001B[1;32m    561\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkey_to_index[key] \u001B[38;5;241m=\u001B[39m target_index\n\u001B[0;32m--> 562\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvectors\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget_index\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m vector\n\u001B[1;32m    563\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext_index \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m target_index\n",
      "\u001B[0;31mValueError\u001B[0m: could not broadcast input array from shape (0,) into shape (400,)"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
