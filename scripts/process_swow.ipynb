{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import corpora\n",
    "from pathlib import Path\n",
    "\n",
    "def get_words(corpus):\n",
    "    words_in_texts = set()\n",
    "    for sentence in corpus.get_texts():\n",
    "        for word in sentence['text']:\n",
    "            words_in_texts.add(word)\n",
    "    return words_in_texts\n",
    "\n",
    "DEACCENT_MAP = {'À': 'A', 'Á': 'A', 'Â': 'A', 'Ã': 'A', 'Ä': 'A',\n",
    "                'à': 'a', 'á': 'a', 'â': 'a', 'ã': 'a', 'ä': 'a',\n",
    "                'È': 'E', 'É': 'E', 'Ê': 'E', 'Ë': 'E',\n",
    "                'è': 'e', 'é': 'e', 'ê': 'e', 'ë': 'e',\n",
    "                'Í': 'I', 'Ì': 'I', 'Î': 'I', 'Ï': 'I',\n",
    "                'í': 'i', 'ì': 'i', 'î': 'i', 'ï': 'i',\n",
    "                'Ò': 'O', 'Ó': 'O', 'Ô': 'O', 'Õ': 'O', 'Ö': 'O',\n",
    "                'ò': 'o', 'ó': 'o', 'ô': 'o', 'õ': 'o', 'ö': 'o',\n",
    "                'Ù': 'U', 'Ú': 'U', 'Û': 'U', 'Ü': 'U',\n",
    "                'ù': 'u', 'ú': 'u', 'û': 'u', 'ü': 'u',\n",
    "                'Ç': 'C', 'ç': 'c'}\n",
    "\n",
    "deaccent_map = str.maketrans(DEACCENT_MAP)\n",
    "root = Path('.').absolute()\n",
    "data_path = root / 'evaluation'\n",
    "texts_path = root / 'texts'\n",
    "\n",
    "texts = corpora.Corpus('texts', 'local', 1.0, min_token_len=2, max_token_len=20, min_sentence_len=None)\n",
    "words_in_texts = get_words(texts)\n",
    "swow = pd.read_csv(data_path / 'SWOWRP_words_associations.csv')\n",
    "swow = swow.drop(swow[~swow['Unnamed: 3'].isna()].index)\n",
    "swow.drop(columns=['Unnamed: 3'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cues with more than one word\n",
    "swow = swow.drop(swow[swow['cue'].str.contains(' ')].index)\n",
    "# Delete cues that are not composed of latin letters\n",
    "swow = swow.drop(swow[swow['cue'].str.contains('[^ \\nA-Za-zÀ-ÖØ-öø-ÿ/]+')].index)\n",
    "# Delete cues with length less than 3\n",
    "swow = swow.drop(swow[swow['cue'].str.len() < 3].index)\n",
    "# Delete cues with length more than 20\n",
    "swow = swow.drop(swow[swow['cue'].str.len() > 20].index)\n",
    "# Deaccent cues\n",
    "swow['cue'] = swow['cue'].str.translate(deaccent_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide in sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cues in texts: 2134\n",
      "Cues outside of texts: 10954\n"
     ]
    }
   ],
   "source": [
    "swow_in_texts = swow.drop(swow[~swow['cue'].isin(words_in_texts)].index)\n",
    "swow_outside_texts = swow.drop(swow[swow['cue'].isin(words_in_texts)].index)\n",
    "print('Cues in texts: ' + str(len(swow_in_texts['cue'].unique())))\n",
    "print('Cues outside of texts: ' + str(len(swow_outside_texts['cue'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "swow_in_texts.to_csv(data_path / 'swow_in_texts.csv', index=False)\n",
    "swow_outside_texts.to_csv(data_path / 'swow_outside_texts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
